{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f057c3b6",
   "metadata": {},
   "source": [
    "# Projet 2 - Fashion Trend Intelligence | Segmentation vestimentaire avec IA\n",
    "\n",
    "Ce notebook permet d‚Äô√©valuer la faisabilit√© technique du mod√®le SegFormer-clothes, afin de d√©terminer s‚Äôil est capable d‚Äôidentifier et d‚Äôisoler avec pr√©cision chaque pi√®ce vestimentaire pr√©sente dans une image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e7c8a",
   "metadata": {},
   "source": [
    "## 1. Installation du projet et de son environnement\n",
    "\n",
    "Afin d‚Äôutiliser correctement ce notebook, v√©rifiez que vous disposez du bon environnement pour l‚Äôex√©cuter.\n",
    "\n",
    "\n",
    "### 1.1 Installation de Python\n",
    "\n",
    "Pour ce projet, il est n√©cessaire d‚Äôavoir **au minimum Python 3.8**.  \n",
    "Si ce n‚Äôest pas d√©j√† le cas, vous pouvez vous r√©f√©rer √† [la documentation officielle](https://www.python.org/downloads/).\n",
    "\n",
    "V√©rifiez votre version de Python :\n",
    "\n",
    "```bash\n",
    "python --version\n",
    "```\n",
    "\n",
    "### 1.2 Installation de `uv`\n",
    "\n",
    "`uv` est un gestionnaire de projets Python permettant d‚Äôinstaller et d‚Äôorganiser les d√©pendances plus rapidement et plus simplement que les outils traditionnels (`pip`, `virtualenv`, etc.).\n",
    "\n",
    "Pour installer `uv`, veuillez suivre [la documentation officielle](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer)\n",
    "\n",
    "V√©rifiez l‚Äôinstallation :\n",
    "\n",
    "```bash\n",
    "uv --version\n",
    "```\n",
    "\n",
    "### 1.3 Cr√©ation du projet\n",
    "\n",
    "Cr√©ez un nouveau projet Python avec `uv` :\n",
    "\n",
    "```bash\n",
    "uv init nom_du_projet\n",
    "cd nom_du_projet\n",
    "```\n",
    "\n",
    "La structure de base du projet est alors g√©n√©r√©e automatiquement.\n",
    "\n",
    "\n",
    "### 1.4 Cr√©ation et activation de l‚Äôenvironnement virtuel\n",
    "\n",
    "Cr√©ez l‚Äôenvironnement virtuel :\n",
    "\n",
    "```bash\n",
    "uv venv\n",
    "```\n",
    "\n",
    "Activez-le selon votre syst√®me :\n",
    "\n",
    "* **Linux / macOS**\n",
    "\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "* **Windows (PowerShell)**\n",
    "\n",
    "```powershell\n",
    ".venv\\Scripts\\Activate.ps1\n",
    "```\n",
    "\n",
    "Voir la documentation officielle :\n",
    "[https://docs.astral.sh/uv/pip/environments/#creating-a-virtual-environment](https://docs.astral.sh/uv/pip/environments/#creating-a-virtual-environment)\n",
    "\n",
    "\n",
    "\n",
    "### 1.5 Installation des d√©pendances\n",
    "\n",
    "> ‚ùó Assurez-vous que l‚Äôenvironnement virtuel est **activ√©** avant d‚Äôinstaller les d√©pendances.\n",
    "\n",
    "Installez les biblioth√®ques n√©cessaires au projet :\n",
    "\n",
    "```bash\n",
    "uv add ipykernel jupyterlab requests pillow matplotlib numpy tqdm python-dotenv aiohttp\n",
    "```\n",
    "\n",
    "Ces d√©pendances sont automatiquement enregistr√©es dans le fichier `pyproject.toml`.\n",
    "\n",
    "Vous pouvez visualiser l‚Äôensemble des d√©pendances install√©es avec la commande suivante :\n",
    "\n",
    "```bash\n",
    "uv tree\n",
    "```\n",
    "\n",
    "### 1.6 Cr√©ation du fichier `.env`\n",
    "\n",
    "Cr√©ez un fichier nomm√© `.env` √† la racine du projet.\n",
    "\n",
    "Copiez-y le contenu suivant et remplacez les valeurs si n√©cessaire :\n",
    "\n",
    "```env\n",
    "# Token d'authentification √† l'API Hugging Face\n",
    "HF_API_TOKEN=VOTRE_TOKEN_HUGGING_FACE_ICI\n",
    "\n",
    "# Chemins du dataset\n",
    "DATASET_IMAGES_DIR=content/images_a_segmenter\n",
    "DATASET_ANNOTATIONS_DIR=content/annotations\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **Important** :\n",
    "\n",
    "* Ne partagez jamais votre fichier `.env`\n",
    "* Ajoutez-le √† votre `.gitignore`\n",
    "\n",
    "```gitignore\n",
    ".env\n",
    "```\n",
    "\n",
    "### 1.7 Cr√©ation d‚Äôun token Hugging Face\n",
    "\n",
    "1. Cr√©ez un compte sur [https://huggingface.co/](https://huggingface.co/)\n",
    "2. Allez dans **Profile ‚Üí Settings ‚Üí Access Tokens**\n",
    "3. Cr√©ez un nouveau token (r√¥le **read** suffisant)\n",
    "4. Copiez le token dans la variable `HF_API_TOKEN` du fichier `.env`\n",
    "\n",
    "\n",
    "### 1.8 Pr√©paration des jeux de donn√©es\n",
    "\n",
    "R√©cup√©rez les jeux de donn√©es (images et annotations) et placez-les dans les dossiers suivants :\n",
    "\n",
    "```\n",
    "content/\n",
    "‚îú‚îÄ‚îÄ images_a_segmenter/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ image_0.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ image_1.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ annotations/\n",
    "    ‚îú‚îÄ‚îÄ mask_0.json\n",
    "    ‚îú‚îÄ‚îÄ mask_1.json\n",
    "    ‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87239d3",
   "metadata": {},
   "source": [
    "## 2. Importation des Biblioth√®ques\n",
    "\n",
    "Commen√ßons par importer les biblioth√®ques Python n√©cessaires. Nous aurons besoin de :\n",
    "- **`os`** : Interaction avec le syst√®me de fichiers (navigation dans les r√©pertoires, listage des fichiers images).\n",
    "- **`requests`** : Envoi de requ√™tes HTTP vers l'API pour la segmentation d'images.\n",
    "- **`PIL (Pillow)`** : Manipulation et traitement des images (ouverture, redimensionnement, conversion).\n",
    "- **`matplotlib.pyplot`** : Visualisation des images originales et des masques de segmentation.\n",
    "- **`matplotlib.patches`** : Cr√©ation d'√©l√©ments graphiques personnalis√©s pour les l√©gendes des visualisations.\n",
    "- **`numpy`** : Manipulation efficace des tableaux num√©riques repr√©sentant les pixels des images.\n",
    "- **`tqdm.notebook`** : Affichage d'une barre de progression interactive dans les notebooks Jupyter (utile lors du traitement par lot).\n",
    "- **`base64`** : Encodage/d√©codage en Base64 des images et masques √©chang√©s avec l'API.\n",
    "- **`io`** : Gestion des flux de donn√©es en m√©moire pour la manipulation des images sans fichiers temporaires.\n",
    "- **`python-dotenv`** : Chargement s√©curis√© des variables d'environnement (comme les cl√©s API) depuis un fichier `.env`.\n",
    "- **`time`** : Gestion des d√©lais entre les appels API pour respecter les limites de taux (rate limiting).\n",
    "- **`re`** : Traitement d'expressions r√©guli√®res (parsing de r√©ponses, validation de formats).\n",
    "- **`aiohttp`** : Requ√™tes HTTP asynchrones pour am√©liorer les performances lors du traitement par lot d'images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import Colormap\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.asyncio import tqdm as async_tqdm\n",
    "import base64\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import re\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from typing import Dict, List, TypedDict, Union, Tuple\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d06005",
   "metadata": {},
   "source": [
    "## 3. Chargement de la Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b649df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# R√©cup√©ration des variables d'environnement\n",
    "IMAGES_DIR = os.getenv('DATASET_IMAGES_DIR')\n",
    "ANNOTATIONS_DIR = os.getenv('DATASET_ANNOTATIONS_DIR')\n",
    "API_TOKEN = os.getenv('HF_API_TOKEN')\n",
    "MAX_IMAGES = 2  # Nombre maximum d'images √† traiter\n",
    "\n",
    "# V√©rification de la pr√©sence des variables\n",
    "if not IMAGES_DIR or not API_TOKEN or not ANNOTATIONS_DIR:\n",
    "    raise ValueError(\"Variables d'environnement manquantes dans le fichier .env\")\n",
    "\n",
    "# V√©rification du token\n",
    "if API_TOKEN == \"VOTRE_TOKEN_HUGGING_FACE_ICI\":\n",
    "    raise ValueError(\"Vous devez remplacer 'VOTRE_TOKEN_HUGGING_FACE_ICI' par votre token API personnel dans le fichier .env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd17ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©fixes pour les fichiers\n",
    "MASK_PREFIX = \"mask_\"\n",
    "IMAGE_FILENAME_SEPARATOR = '_'\n",
    "IMAGE_NUMBER_INDEX = 1\n",
    "\n",
    "# Type alias pour am√©liorer la lisibilit√©\n",
    "PathLike = Union[Path, str]\n",
    "\n",
    "def validate_file_exists(path: PathLike, file_type: str) -> bool:\n",
    "    \"\"\"V√©rifie l'existence d'un fichier et log si absent.\"\"\"\n",
    "    if not Path(path).exists():\n",
    "        print(f\"{file_type} introuvable: {path}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def natural_sort_key(path):\n",
    "        filename = os.path.basename(path)\n",
    "        # Extraire les nombres du nom de fichier\n",
    "        return [int(text) if text.isdigit() else text.lower() \n",
    "                for text in re.split('([0-9]+)', filename)]\n",
    "\n",
    "def get_image_paths(\n",
    "    images_dir: str = None,\n",
    "    max_images: int = None,\n",
    "    extensions: Tuple[str, ...] = ('.png', '.jpg', '.jpeg'),\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    R√©cup√®re et trie les chemins des images √† traiter.\n",
    "    \n",
    "    Args:\n",
    "        images_dir: R√©pertoire contenant les images (par d√©faut: IMAGES_DIR)\n",
    "        max_images: Nombre maximum d'images (par d√©faut: MAX_IMAGES)\n",
    "        extensions: Extensions de fichiers accept√©es\n",
    "    \n",
    "    Returns:\n",
    "        Liste des chemins d'images tri√©s naturellement et valid√©s\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: Si le r√©pertoire n'existe pas\n",
    "        NotADirectoryError: Si le chemin n'est pas un r√©pertoire\n",
    "    \"\"\"\n",
    "    # Utiliser les valeurs par d√©faut si non fournies\n",
    "    images_dir = Path(images_dir)\n",
    "    \n",
    "    # V√©rifier l'existence du r√©pertoire avec validate_file_exists\n",
    "    if not Path(images_dir).exists():\n",
    "        raise FileNotFoundError(f\"Le r√©pertoire '{images_dir}' n'existe pas\")\n",
    "    \n",
    "    if not images_dir.is_dir():\n",
    "        raise NotADirectoryError(f\"'{images_dir}' n'est pas un r√©pertoire\")\n",
    "    \n",
    "    # R√©cup√©rer tous les fichiers avec les bonnes extensions\n",
    "    image_paths = [\n",
    "        images_dir / f \n",
    "        for f in os.listdir(images_dir) \n",
    "        if f.lower().endswith(extensions)\n",
    "    ]\n",
    "    \n",
    "    # Messages informatifs\n",
    "    if not image_paths:\n",
    "        print(f\"‚ö†Ô∏è  Aucune image valide trouv√©e dans '{images_dir}'\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"‚úÖ {len(image_paths)} image(s) valide(s) trouv√©e(s)\")\n",
    "    \n",
    "    # Tri naturel\n",
    "    image_paths.sort(key=natural_sort_key)\n",
    "    \n",
    "    # Limitation\n",
    "    original_count = len(image_paths)\n",
    "    image_paths = image_paths[:max_images]\n",
    "    \n",
    "    if len(image_paths) < original_count:\n",
    "        print(f\"‚öôÔ∏è  Limitation appliqu√©e: {len(image_paths)}/{original_count} images\")\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "def get_mask_paths(\n",
    "    image_paths: List[PathLike],\n",
    "    masks_dir: str,\n",
    "    mask_prefix: str = \"mask_\"\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    R√©cup√®re les chemins des masques (ground truth ou pr√©dits).\n",
    "    \n",
    "    Args:\n",
    "        image_paths: Liste des chemins des images\n",
    "        masks_dir: R√©pertoire contenant les masques\n",
    "        mask_prefix: Pr√©fixe des fichiers de masques\n",
    "    \n",
    "    Returns:\n",
    "        Liste des chemins des masques (None si masque absent)\n",
    "    \"\"\"\n",
    "    mask_paths = []\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        # Extraire le num√©ro de l'image\n",
    "        filename = Path(image_path).name\n",
    "        parts = filename.split(IMAGE_FILENAME_SEPARATOR)\n",
    "        image_number = parts[IMAGE_NUMBER_INDEX].split('.')[0]\n",
    "\n",
    "        # Chemin vers le masque\n",
    "        mask_path = Path(masks_dir) / f\"{mask_prefix}{image_number}.png\"\n",
    "        \n",
    "        # Validation de l'existence du masque\n",
    "        if validate_file_exists(mask_path, f\"Masque ({mask_prefix})\"):\n",
    "            mask_paths.append(mask_path)\n",
    "        else:\n",
    "            mask_paths.append(None)\n",
    "    \n",
    "    return mask_paths\n",
    "\n",
    "def get_gt_mask_paths(image_paths: List[PathLike]) -> List[Path]:\n",
    "    \"\"\"R√©cup√®re les chemins des masques ground truth.\"\"\"\n",
    "    return get_mask_paths(\n",
    "        image_paths=image_paths,\n",
    "        masks_dir=ANNOTATIONS_DIR,\n",
    "        mask_prefix=MASK_PREFIX\n",
    "    )\n",
    "\n",
    "# Cr√©ation des dossiers s'ils n'existent pas\n",
    "for directory, name in [(IMAGES_DIR, \"images\"), (ANNOTATIONS_DIR, \"annotations\")]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"‚úì Dossier '{directory}' cr√©√© pour les {name}.\")\n",
    "    else:\n",
    "        print(f\"‚úì Dossier '{directory}' existant.\")\n",
    "\n",
    "image_paths = get_image_paths(IMAGES_DIR, MAX_IMAGES)\n",
    "gt_mask_paths = get_gt_mask_paths(image_paths)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(gt_mask_paths)} annotations charg√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095821a",
   "metadata": {},
   "source": [
    "## 4. Configuration de l'API Hugging Face\n",
    "\n",
    "### 4.1 Pr√©sentation du mod√®le\n",
    "Nous utilisons le mod√®le [**SegFormer-B3-Clothes**](https://huggingface.co/sayeed99/segformer_b3_clothes) qui est sp√©cialis√© dans la segmentation s√©mantique de v√™tements. Ce mod√®le peut d√©tecter 18 classes diff√©rentes :\n",
    "- √âl√©ments vestimentaires : chapeau, haut, jupe, pantalon, robe, ceinture, chaussures, sac, √©charpe\n",
    "- Parties du corps : cheveux, visage, bras, jambes\n",
    "- Accessoires : lunettes de soleil\n",
    "- Arri√®re-plan\n",
    "\n",
    "### 4.2 Configuration de l'endpoint API\n",
    "L'API Hugging Face Inference Router permet d'interroger le mod√®le sans avoir √† le d√©ployer localement. Voici les √©l√©ments de configuration :\n",
    "\n",
    "**URL de l'API** : `https://router.huggingface.co/hf-inference/models/sayeed99/segformer_b3_clothes`\n",
    "\n",
    "**Headers requis** :\n",
    "- `Authorization: Bearer YOUR_TOKEN` : Authentification avec votre token personnel\n",
    "- `Content-Type: image/jpeg` ou `image/png` : Type MIME de l'image envoy√©e\n",
    "\n",
    "**Format de r√©ponse** : L'API retourne un JSON contenant une liste de masques encod√©s en base64, un par classe d√©tect√©e.\n",
    "\n",
    "**S√©curit√©** : Ne jamais hardcoder votre token dans le notebook. Elle doit mis dans la variable d'environnement `HF_API_TOKEN'` le fichier `.env`\n",
    "\n",
    "### 4.3 Bonnes pratiques d'utilisation\n",
    "1. **Rate Limiting** : Espacer les requ√™tes de 1-2 secondes pour √©viter les erreurs 429 (Too Many Requests)\n",
    "2. **Timeout** : D√©finir un timeout de 30 secondes minimum (le mod√®le peut √™tre lent)\n",
    "3. **Gestion d'erreurs** : Pr√©voir les cas suivants :\n",
    "   - 401 : Token invalide\n",
    "   - 429 : Trop de requ√™tes\n",
    "   - 500 : Erreur serveur (r√©essayer apr√®s quelques secondes)\n",
    "   - 503 : Mod√®le en cours de chargement (attendre et r√©essayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://router.huggingface.co/hf-inference/models/sayeed99/segformer_b3_clothes\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\"\n",
    "    # Le \"Content-Type\" sera ajout√© dynamiquement lors de l'envoi de l'image\n",
    "}\n",
    "\n",
    "\n",
    "# Rate limiting pour compte gratuit (d'apr√®s la doc HF)\n",
    "# Inference API : ~1000 requ√™tes/jour, avec burst de ~100 requ√™tes/min\n",
    "REQUESTS_PER_MINUTE = 30  # On reste prudent (bien en dessous de 100)\n",
    "DELAY_BETWEEN_REQUESTS = 60 / REQUESTS_PER_MINUTE  # ~2 secondes entre chaque requ√™te\n",
    "\n",
    "\n",
    "# Configuration des requ√™tes asynchrones\n",
    "MAX_CONCURRENT_REQUESTS = 5      # Nombre de requ√™tes simultan√©es maximum\n",
    "MAX_RETRIES = 3                  # Nombre de tentatives en cas d'erreur\n",
    "INITIAL_RETRY_DELAY = 2          # D√©lai initial entre les tentatives (secondes)\n",
    "REQUEST_TIMEOUT = 30             # Timeout des requ√™tes (secondes)\n",
    "\n",
    "CLASS_MAPPING = {\n",
    "    \"Background\": 0,\n",
    "    \"Hat\": 1,\n",
    "    \"Hair\": 2,\n",
    "    \"Sunglasses\": 3,\n",
    "    \"Upper-clothes\": 4,\n",
    "    \"Skirt\": 5,\n",
    "    \"Pants\": 6,\n",
    "    \"Dress\": 7,\n",
    "    \"Belt\": 8,\n",
    "    \"Left-shoe\": 9,\n",
    "    \"Right-shoe\": 10,\n",
    "    \"Face\": 11,\n",
    "    \"Left-leg\": 12,\n",
    "    \"Right-leg\": 13,\n",
    "    \"Left-arm\": 14,\n",
    "    \"Right-arm\": 15,\n",
    "    \"Bag\": 16,\n",
    "    \"Scarf\": 17\n",
    "}\n",
    "\n",
    "def get_image_dimensions(img_path):\n",
    "    \"\"\"\n",
    "    Get the dimensions of an image.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (width, height) of the image.\n",
    "    \"\"\"\n",
    "    original_image = Image.open(img_path)\n",
    "    return original_image.size\n",
    "\n",
    "def decode_base64_mask(base64_string, width, height):\n",
    "    \"\"\"\n",
    "    Decode a base64-encoded mask into a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        base64_string (str): Base64-encoded mask.\n",
    "        width (int): Target width.\n",
    "        height (int): Target height.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Single-channel mask array.\n",
    "    \"\"\"\n",
    "    mask_data = base64.b64decode(base64_string)\n",
    "    mask_image = Image.open(io.BytesIO(mask_data))\n",
    "    mask_array = np.array(mask_image)\n",
    "    if len(mask_array.shape) == 3:\n",
    "        mask_array = mask_array[:, :, 0]  # Take first channel if RGB\n",
    "    mask_image = Image.fromarray(mask_array).resize((width, height), Image.NEAREST)\n",
    "    return np.array(mask_image)\n",
    "\n",
    "def create_masks(results, width, height):\n",
    "    \"\"\"\n",
    "    Combine multiple class masks into a single segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of dictionaries with 'label' and 'mask' keys.\n",
    "        width (int): Target width.\n",
    "        height (int): Target height.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Combined segmentation mask with class indices.\n",
    "    \"\"\"\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)  # Initialize with Background (0)\n",
    "\n",
    "    # Process non-Background masks first\n",
    "    for result in results:\n",
    "        label = result['label']\n",
    "        class_id = CLASS_MAPPING.get(label, 0)\n",
    "        if class_id == 0:  # Skip Background\n",
    "            continue\n",
    "        mask_array = decode_base64_mask(result['mask'], width, height)\n",
    "        combined_mask[mask_array > 0] = class_id\n",
    "\n",
    "    # Process Background last to ensure it doesn't overwrite other classes unnecessarily\n",
    "    # (Though the model usually provides non-overlapping masks for distinct classes other than background)\n",
    "    for result in results:\n",
    "        if result['label'] == 'Background':\n",
    "            mask_array = decode_base64_mask(result['mask'], width, height)\n",
    "            # Apply background only where no other class has been assigned yet\n",
    "            # This logic might need adjustment based on how the model defines 'Background'\n",
    "            # For this model, it seems safer to just let non-background overwrite it first.\n",
    "            # A simple application like this should be fine: if Background mask says pixel is BG, set it to 0.\n",
    "            # However, a more robust way might be to only set to background if combined_mask is still 0 (initial value)\n",
    "            combined_mask[mask_array > 0] = 0 # Class ID for Background is 0\n",
    "\n",
    "    return combined_mask\n",
    "\n",
    "async def segment_clothes_async(\n",
    "    session: aiohttp.ClientSession,\n",
    "    single_image_path: str,\n",
    "    semaphore: asyncio.Semaphore\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Requ√™te asynchrone √† l'API Hugging Face avec rate limiting.\n",
    "\n",
    "    Args:\n",
    "        session: Session aiohttp partag√©e\n",
    "        single_image_path: Chemin vers l'image √† segmenter\n",
    "        semaphore: S√©maphore pour limiter les requ√™tes concurrentes\n",
    "\n",
    "    Returns:\n",
    "        dict: R√©sultats de la segmentation (JSON de l'API)\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: Si le fichier image n'existe pas\n",
    "        ValueError: Si le format d'image n'est pas support√©\n",
    "        aiohttp.ClientError: Si la requ√™te API √©choue\n",
    "    \"\"\"\n",
    "    \n",
    "    # V√©rification de l'existence du fichier\n",
    "    if not os.path.exists(single_image_path):\n",
    "        raise FileNotFoundError(f\"L'image '{single_image_path}' n'existe pas\")\n",
    "    \n",
    "    # V√©rification du format d'image\n",
    "    try:\n",
    "        with Image.open(single_image_path) as img:\n",
    "            image_format = img.format\n",
    "            \n",
    "            if image_format not in ['JPEG', 'PNG']:\n",
    "                raise ValueError(\n",
    "                    f\"Format '{image_format}' non support√©. \"\n",
    "                    f\"Formats accept√©s: JPEG, PNG\"\n",
    "                )\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Impossible d'ouvrir l'image: {e}\")\n",
    "    \n",
    "    # Lecture du contenu binaire\n",
    "    try:\n",
    "        with open(single_image_path, 'rb') as fichier:\n",
    "            image_data = fichier.read()\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"Erreur lors de la lecture du fichier: {e}\")\n",
    "    \n",
    "    # Configuration des headers\n",
    "    request_headers = headers.copy()\n",
    "    request_headers[\"Content-Type\"] = f\"image/{image_format.lower()}\"\n",
    "    \n",
    "    # Utilisation du s√©maphore pour limiter les requ√™tes concurrentes\n",
    "    async with semaphore:\n",
    "        retry_delay = INITIAL_RETRY_DELAY\n",
    "        \n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                async with session.post(\n",
    "                    API_URL,\n",
    "                    headers=request_headers,\n",
    "                    data=image_data,\n",
    "                    timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)\n",
    "                ) as response:\n",
    "                    \n",
    "                    # Gestion des diff√©rents codes de statut\n",
    "                    if response.status == 503:\n",
    "                        # Mod√®le en cours de chargement\n",
    "                        print(f\"‚è≥ Mod√®le en chargement, attente {INITIAL_RETRY_DELAY}s...\")\n",
    "                        await asyncio.sleep(INITIAL_RETRY_DELAY)\n",
    "                        retry_delay *= 2  # Backoff exponentiel\n",
    "                        continue\n",
    "                    \n",
    "                    elif response.status == 429:\n",
    "                        # Rate limit atteint\n",
    "                        retry_after = response.headers.get('Retry-After', retry_delay)\n",
    "                        wait_time = int(retry_after) if isinstance(retry_after, str) and retry_after.isdigit() else retry_delay\n",
    "                        print(f\"‚ö†Ô∏è Rate limit atteint, attente {wait_time}s...\")\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                        continue\n",
    "                    \n",
    "                    elif response.status == 401:\n",
    "                        raise ValueError(\"Token API invalide ou expir√©\")\n",
    "                    \n",
    "                    elif response.status >= 500:\n",
    "                        # Erreur serveur, on r√©essaie\n",
    "                        if attempt < MAX_RETRIES - 1:\n",
    "                            print(f\"‚ùå Erreur serveur (5xx), nouvelle tentative dans {retry_delay}s...\")\n",
    "                            await asyncio.sleep(retry_delay)\n",
    "                            retry_delay *= 2\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise aiohttp.ClientError(\n",
    "                                f\"Erreur serveur persistante (status {response.status})\"\n",
    "                            )\n",
    "                    \n",
    "                    # V√©rification du statut\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    # Parsing de la r√©ponse\n",
    "                    results = await response.json()\n",
    "                    print(f\"‚úÖ R√©ponse re√ßue pour {os.path.basename(single_image_path)}\")\n",
    "                    \n",
    "                    # D√©lai entre les requ√™tes pour respecter le rate limit\n",
    "                    await asyncio.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "                    \n",
    "                    return results\n",
    "                    \n",
    "            except asyncio.TimeoutError:\n",
    "                if attempt < MAX_RETRIES - 1:\n",
    "                    print(f\"‚è±Ô∏è Timeout, nouvelle tentative...\")\n",
    "                    await asyncio.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise asyncio.TimeoutError(\n",
    "                        f\"Timeout apr√®s {MAX_RETRIES} tentatives pour '{single_image_path}'\"\n",
    "                    )\n",
    "            \n",
    "            except aiohttp.ClientError as e:\n",
    "                if attempt < MAX_RETRIES - 1:\n",
    "                    print(f\"‚ùå Erreur r√©seau, nouvelle tentative dans {retry_delay}s...\")\n",
    "                    await asyncio.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise\n",
    "        \n",
    "        raise Exception(f\"√âchec apr√®s {MAX_RETRIES} tentatives\")\n",
    "\n",
    "\n",
    "async def segment_clothes_batch(image_paths: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Segmente un lot d'images de mani√®re asynchrone avec rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        image_paths: Liste des chemins d'images √† traiter\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: Liste des r√©sultats de segmentation\n",
    "    \"\"\"\n",
    "    # S√©maphore pour limiter les requ√™tes concurrentes\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [\n",
    "            segment_clothes_async(session, img_path, semaphore)\n",
    "            for img_path in image_paths\n",
    "        ]\n",
    "        \n",
    "        # Ex√©cution de toutes les t√¢ches\n",
    "        results = await async_tqdm.gather(*tasks, desc=\"Segmentation\")        \n",
    "        \n",
    "        # Traitement des r√©sultats et des erreurs\n",
    "        processed_results = []\n",
    "        for i, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"‚ùå Erreur pour {image_paths[i]}: {result}\")\n",
    "                processed_results.append(None)\n",
    "            else:\n",
    "                width, height = get_image_dimensions(image_paths[i])\n",
    "                processed_results.append(create_masks(result, width, height))\n",
    "        \n",
    "        return processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc3dd5",
   "metadata": {},
   "source": [
    "## 5. Visualisation des annotations (Ground Truth)\n",
    "\n",
    "Ces annotations serviront de r√©f√©rence pour √©valuer la qualit√© des pr√©dictions du mod√®le dans les sections suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifiant de la classe background\n",
    "BACKGROUND_CLASS_ID = 0\n",
    "\n",
    "# Configuration de la l√©gende\n",
    "LEGEND_CONFIG = {\n",
    "    'loc': 'upper left',\n",
    "    'frameon': False,\n",
    "    'handlelength': 1,\n",
    "    'handleheight': 1,\n",
    "    'handletextpad': 0.4,\n",
    "    'labelcolor': 'white',\n",
    "}\n",
    "\n",
    "# Configuration de la figure\n",
    "FIGURE_WIDTH = 18\n",
    "FIGURE_HEIGHT = 6\n",
    "OVERLAY_ALPHA = 0.5\n",
    "\n",
    "# Nom de la colormap\n",
    "COLORMAP_NAME = 'tab20'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ImageInfo(TypedDict):\n",
    "    \"\"\"Informations d√©taill√©es sur l'image.\"\"\"\n",
    "    image_size: Tuple[int, int]\n",
    "    image_mode: str\n",
    "    mask_size: Tuple[int, int]\n",
    "    unique_classes: List[int]\n",
    "    num_classes: int\n",
    "    class_distribution: Dict[int, int]\n",
    "\n",
    "class VerificationResult(TypedDict):\n",
    "    \"\"\"R√©sultat de la v√©rification d'une paire image/masque.\"\"\"\n",
    "    warnings: List[str]\n",
    "    info: ImageInfo\n",
    "\n",
    "def get_legend_elements(\n",
    "    mask_array: npt.NDArray[np.int32],\n",
    "    id_to_class: Dict[int, str],\n",
    "    color_map: Colormap,\n",
    "    num_classes: int\n",
    ") -> List[Patch]:\n",
    "    \"\"\"\n",
    "    Cr√©e les √©l√©ments de l√©gende pour les classes pr√©sentes dans le masque.\n",
    "    \n",
    "    Args:\n",
    "        mask_array: Tableau 2D repr√©sentant le masque de segmentation\n",
    "        id_to_class: Mapping {id_classe: nom_classe}\n",
    "        color_map: Colormap matplotlib\n",
    "        num_classes: Nombre total de classes\n",
    "    \n",
    "    Returns:\n",
    "        Liste d'objets Patch pour la l√©gende matplotlib\n",
    "    \"\"\"\n",
    "    unique_classes = np.unique(mask_array)\n",
    "    legend_elements = []\n",
    "    \n",
    "    for class_id in unique_classes:\n",
    "        if class_id in id_to_class:\n",
    "            # Normalisation pour la colormap [0, 1]\n",
    "            normalized_id = class_id / (num_classes - 1)\n",
    "            color = color_map(normalized_id)\n",
    "            legend_elements.append(\n",
    "                Patch(facecolor=color, label=id_to_class[class_id])\n",
    "            )\n",
    "    \n",
    "    return legend_elements\n",
    "\n",
    "\n",
    "def verify_image_mask_pair(\n",
    "    original_image: Image.Image,\n",
    "    mask_image: Image.Image,\n",
    "    max_class_id: int\n",
    ") -> VerificationResult:\n",
    "    \"\"\"\n",
    "    V√©rifie la validit√© et la coh√©rence d'une paire image/masque.\n",
    "    \n",
    "    Args:\n",
    "        original_image: Image originale\n",
    "        mask_image: Masque d'annotation correspondant\n",
    "        max_class_id: ID de classe maximum attendu\n",
    "\n",
    "    Returns:\n",
    "        R√©sultats de la v√©rification avec cl√©s 'warnings', 'info'\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'warnings': [],\n",
    "        'info': {}\n",
    "    }\n",
    "    \n",
    "    # V√©rifier les dimensions\n",
    "    if original_image.size != mask_image.size:\n",
    "        result['warnings'].append(\n",
    "            f\"Dimensions diff√©rentes - Image: {original_image.size}, \"\n",
    "            f\"Masque: {mask_image.size}\"\n",
    "        )\n",
    "    \n",
    "    # V√©rifier le mode de l'image\n",
    "    valid_image_modes = ['RGB', 'RGBA', 'L']\n",
    "    if original_image.mode not in valid_image_modes:\n",
    "        result['warnings'].append(f\"Mode d'image inhabituel: {original_image.mode}\")\n",
    "\n",
    "    # Analyser le masque\n",
    "    mask_array = np.array(mask_image)\n",
    "    unique_classes = np.unique(mask_array)\n",
    "    \n",
    "    # V√©rifier les valeurs des classes\n",
    "    invalid_classes = [c for c in unique_classes if c > max_class_id]\n",
    "    if invalid_classes:\n",
    "        result['warnings'].append(\n",
    "            f\"Classes invalides d√©tect√©es: {invalid_classes} \"\n",
    "            f\"(max attendu: {max_class_id})\"\n",
    "        )\n",
    "    \n",
    "    # V√©rifier si le masque est vide (que du background)\n",
    "    if len(unique_classes) == 1 and unique_classes[0] == BACKGROUND_CLASS_ID:\n",
    "        result['warnings'].append(\"Masque vide (que du background)\")\n",
    "    \n",
    "    # Informations suppl√©mentaires\n",
    "    result['info'] = {\n",
    "        'image_size': original_image.size,\n",
    "        'image_mode': original_image.mode,\n",
    "        'mask_size': mask_image.size,\n",
    "        'unique_classes': unique_classes.tolist(),\n",
    "        'num_classes': len(unique_classes),\n",
    "        'class_distribution': {\n",
    "            int(class_id): int(np.sum(mask_array == class_id)) \n",
    "            for class_id in unique_classes\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_visualization_figure(\n",
    "    original_image: Image.Image,\n",
    "    mask_image: Image.Image,\n",
    "    image_name: str,\n",
    "    mask_array: npt.NDArray[np.int32],\n",
    "    id_to_class: Dict[int, str],\n",
    "    color_map: Colormap,\n",
    "    num_classes: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Cr√©e et affiche une figure de visualisation avec 3 subplots.\n",
    "    \n",
    "    Args:\n",
    "        original_image: Image originale\n",
    "        mask_image: Masque d'annotation\n",
    "        image_number: Num√©ro de l'image pour le titre\n",
    "        mask_array: Tableau numpy du masque pour la l√©gende\n",
    "        id_to_class: Mapping {id_classe: nom_classe}\n",
    "        color_map: Colormap matplotlib\n",
    "        num_classes: Nombre total de classes\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(FIGURE_WIDTH, FIGURE_HEIGHT))\n",
    "\n",
    "    # Image originale\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title(f\"Image : {image_name}\", fontsize=12, fontweight='bold')\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # Masque d'annotation\n",
    "    axes[1].imshow(\n",
    "        mask_image,\n",
    "        cmap=color_map,\n",
    "        vmin=0,\n",
    "        vmax=num_classes - 1\n",
    "    )\n",
    "    axes[1].set_title(\"Annotation\", fontsize=12, fontweight='bold')\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    # Overlay (image + masque transparent)\n",
    "    axes[2].imshow(original_image)\n",
    "    axes[2].imshow(\n",
    "        mask_image,\n",
    "        cmap=color_map,\n",
    "        alpha=OVERLAY_ALPHA,\n",
    "        vmin=0,\n",
    "        vmax=num_classes - 1\n",
    "    )\n",
    "    axes[2].set_title(\"Overlay\", fontsize=12, fontweight='bold')\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    # Ajouter les l√©gendes\n",
    "    legend_elements = get_legend_elements(mask_array, id_to_class, color_map, num_classes)\n",
    "    axes[1].legend(handles=legend_elements, **LEGEND_CONFIG)\n",
    "    axes[2].legend(handles=legend_elements, **LEGEND_CONFIG)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def display_images_with_masks(\n",
    "    image_paths: List[PathLike],\n",
    "    gt_mask_paths: List[PathLike],\n",
    "    class_mapping: Dict[str, int]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Affiche un batch d'images avec leurs masques d'annotation.\n",
    "    \n",
    "    Args:\n",
    "        image_paths: Liste des chemins des images √† afficher\n",
    "        gt_mask_paths: Liste des chemins des masques d'annotation\n",
    "        class_mapping: Dictionnaire {nom_classe: id_classe}\n",
    "    \"\"\"\n",
    "    if not image_paths:\n",
    "        print(\"Aucune image √† afficher.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    id_to_class = {v: k for k, v in class_mapping.items()}\n",
    "    color_map = plt.colormaps.get_cmap(COLORMAP_NAME).resampled(len(class_mapping))\n",
    "    max_class_id = max(class_mapping.values())\n",
    "    num_classes = len(class_mapping)\n",
    "    \n",
    "    stats = {\n",
    "        'total': len(image_paths),\n",
    "        'displayed': 0,\n",
    "        'warnings': 0,\n",
    "        'images_not_found': 0,\n",
    "        'masks_not_found': 0,\n",
    "        'error': 0\n",
    "    }\n",
    "\n",
    "    for image_index, (image_path, gt_mask_path) in enumerate(zip(image_paths, gt_mask_paths), 1):\n",
    "        print(f\"\\n[{image_index}/{stats['total']}] Traitement de: {image_path}\")\n",
    "\n",
    "        try:\n",
    "            # V√©rifier l'existence des fichiers\n",
    "            if not validate_file_exists(image_path, \"Image\"):\n",
    "                stats['images_not_found'] += 1\n",
    "                continue\n",
    "\n",
    "            if not validate_file_exists(gt_mask_path, \"Annotation\"):\n",
    "                stats['masks_not_found'] += 1\n",
    "                continue\n",
    "\n",
    "            original_image = Image.open(image_path)\n",
    "            mask_image = Image.open(gt_mask_path)\n",
    "\n",
    "            verification = verify_image_mask_pair(original_image, mask_image, max_class_id)\n",
    "            \n",
    "            if verification['warnings']:\n",
    "                stats['warnings'] += 1\n",
    "                print(f\"‚ö†Ô∏è  AVERTISSEMENTS:\")\n",
    "                for warning in verification['warnings']:\n",
    "                    print(f\"   - {warning}\")\n",
    "            \n",
    "            if verification['info']:\n",
    "                info = verification['info']\n",
    "                print(f\"‚ÑπÔ∏è  INFORMATIONS:\")\n",
    "                print(f\"   - Dimensions: {info['image_size']}\")\n",
    "                print(f\"   - Nombre de classes pr√©sentes: {info['num_classes']}\")\n",
    "                print(f\"   - Classes d√©tect√©es: {info['unique_classes']}\")\n",
    "\n",
    "            # Cr√©er la visualisation\n",
    "            mask_array = np.array(mask_image, dtype=np.int32)\n",
    "            create_visualization_figure(\n",
    "                original_image,\n",
    "                mask_image,\n",
    "                image_path.name,\n",
    "                mask_array,\n",
    "                id_to_class,\n",
    "                color_map,\n",
    "                num_classes\n",
    "            )\n",
    "            stats['displayed'] += 1\n",
    "        except ValueError as e:\n",
    "            print(f\"‚ùå Erreur: {e}\")\n",
    "            stats['error'] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur inattendue: {type(e).__name__}: {e}\")\n",
    "            stats['error'] += 1\n",
    "\n",
    "    # R√©sum√© final\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä R√âSUM√â DE LA V√âRIFICATION:\")\n",
    "    print(f\"  ‚Ä¢ Total d'images: {stats['total']}\")\n",
    "    print(f\"  ‚Ä¢ Images affich√©es: {stats['displayed']}\")\n",
    "    print(f\"  ‚Ä¢ Images avec warnings: {stats['warnings']}\")\n",
    "    print(f\"  ‚Ä¢ Images manquantes: {stats['images_not_found']}\")\n",
    "    print(f\"  ‚Ä¢ Masques manquants: {stats['masks_not_found']}\")\n",
    "    print(f\"  ‚Ä¢ Erreurs de traitement: {stats['error']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Afficher les r√©sultats du batch\n",
    "display_images_with_masks(\n",
    "    image_paths=image_paths[:MAX_IMAGES],\n",
    "    gt_mask_paths=gt_mask_paths,\n",
    "    class_mapping=CLASS_MAPPING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60629b",
   "metadata": {},
   "source": [
    "## 6. Segmentation des Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c19c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def segment_images(image_paths: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_paths: Liste des chemins d'images (ou chemin unique)\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict] ou Dict: R√©sultats de la segmentation\n",
    "    \"\"\"\n",
    "    # Accepter un seul chemin ou une liste\n",
    "    if isinstance(image_paths, str):\n",
    "        image_paths = [image_paths]\n",
    "    \n",
    "    print(f\"üöÄ D√©but de la segmentation de {len(image_paths)} image(s)...\")\n",
    "    print(f\"‚è±Ô∏è D√©lai entre requ√™tes: {DELAY_BETWEEN_REQUESTS:.2f}s\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Ex√©cution asynchrone\n",
    "    results = await segment_clothes_batch(image_paths)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Traitement termin√© en {duration:.2f}s\")\n",
    "    print(f\"üìä Succ√®s: {sum(1 for r in results if r is not None)}/{len(image_paths)}\")\n",
    "    print(f\"‚ö° Vitesse moyenne: {len(image_paths)/duration:.2f} images/seconde\")\n",
    "\n",
    "    # Si une seule image, retourner directement le r√©sultat\n",
    "    if len(image_paths) == 1:\n",
    "        return results[0]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def save_masks(\n",
    "    predicted_masks: List[np.ndarray],\n",
    "    image_paths: List[PathLike],\n",
    "    output_dir: str = \"content/results\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Enregistre les masques de segmentation pr√©dits au format PNG.\n",
    "    \n",
    "    Args:\n",
    "        predicted_masks: Liste des masques pr√©dits (NumPy arrays)\n",
    "        image_paths: Liste des chemins des images originales\n",
    "        output_dir: R√©pertoire de sortie pour les masques\n",
    "    \"\"\"\n",
    "    # Cr√©er le dossier s'il n'existe pas\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    saved_count = 0\n",
    "    \n",
    "    for img_path, pred_mask in zip(image_paths, predicted_masks):\n",
    "        if pred_mask is None:\n",
    "            print(f\"‚ö†Ô∏è Pas de masque √† sauvegarder pour {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Extraire le nom de fichier original\n",
    "        img_filename = Path(img_path).stem  # ex: \"image_0\"\n",
    "        \n",
    "        # Cr√©er le nom du fichier de sortie\n",
    "        output_filename = f\"pred_mask_{img_filename}.png\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        # Convertir le masque en image PIL et sauvegarder\n",
    "        mask_image = Image.fromarray(pred_mask.astype(np.uint8))\n",
    "        mask_image.save(output_path)\n",
    "        \n",
    "        saved_count += 1\n",
    "        print(f\"‚úÖ Masque sauvegard√© : {output_path}\")\n",
    "    \n",
    "    print(f\"\\nüìä Total : {saved_count}/{len(image_paths)} masques sauvegard√©s dans '{output_dir}'\")\n",
    "\n",
    "\n",
    "\n",
    "batch_seg_results = []\n",
    "# Appeler la fonction pour segmenter les images list√©es dans image_paths\n",
    "if image_paths:\n",
    "    print(f\"\\nTraitement de {len(image_paths)} image(s) en batch...\")\n",
    "    batch_seg_results = await segment_images(image_paths)\n",
    "\n",
    "    # Sauvegarder les masques pr√©dits\n",
    "    save_masks(batch_seg_results, image_paths, output_dir=\"content/results\")\n",
    "    print(\"Traitement en batch termin√©.\")\n",
    "\n",
    "else:\n",
    "    print(\"Aucune image √† traiter en batch.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fcb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd9d9a46",
   "metadata": {},
   "source": [
    "## 7. Visualisation des Pr√©dictions du Mod√®le\n",
    "\n",
    "Cette section affiche les pr√©dictions g√©n√©r√©es par le mod√®le SegFormer via l'API Hugging Face. Pour chaque image :\n",
    "- **Image originale** : Photo source envoy√©e √† l'API\n",
    "- **Masque segment√©** : Pr√©diction du mod√®le (masque de segmentation g√©n√©r√©)\n",
    "- **Overlay** : Superposition de la pr√©diction sur l'image originale avec transparence\n",
    "\n",
    "Ces visualisations permettent d'√©valuer qualitativement la capacit√© du mod√®le √† segmenter les diff√©rentes classes vestimentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_mask_paths(image_paths: List[PathLike]) -> List[Path]:\n",
    "    \"\"\"R√©cup√®re les chemins des masques pr√©dits.\"\"\"\n",
    "    return get_mask_paths(\n",
    "        image_paths=image_paths,\n",
    "        masks_dir=\"content/results\",\n",
    "        mask_prefix=\"pred_mask_image_\"\n",
    "    )\n",
    "pred_mask_paths = get_predicted_mask_paths(image_paths)\n",
    "print(f\"\\n‚úÖ {len(pred_mask_paths)} masques pr√©dits charg√©s\")\n",
    "\n",
    "if pred_mask_paths :\n",
    "    display_images_with_masks(image_paths, pred_mask_paths, CLASS_MAPPING)\n",
    "else:\n",
    "    print(\"Aucun r√©sultat de segmentation √† afficher.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9952775c",
   "metadata": {},
   "source": [
    "## 8. Comparaison visuelle avec les annotations Ground Truth\n",
    "\n",
    "Cette fonction affiche une comparaison c√¥te √† c√¥te entre les masques de segmentation pr√©dits par le mod√®le et les annotations ground truth. Cela permet d'√©valuer visuellement la qualit√© des pr√©dictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af411e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison_with_ground_truth(image_paths, gt_mask_paths, pred_mask_paths):\n",
    "    \"\"\"\n",
    "    Affiche une comparaison visuelle entre les pr√©dictions et les annotations ground truth.\n",
    "    \n",
    "    Disposition: Image Originale | Overlay Ground Truth | Overlay Pr√©diction\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): Liste des chemins des images originales\n",
    "        gt_mask_paths (list): Liste des chemins des masques ground truth\n",
    "        pred_mask_paths (list): Liste des chemins des masques pr√©dits\n",
    "    \"\"\"\n",
    "    for image_path, gt_mask_path, pred_mask_path in zip(image_paths, gt_mask_paths, pred_mask_paths):\n",
    "    \n",
    "        id_to_class = {v: k for k, v in CLASS_MAPPING.items()}\n",
    "        color_map = plt.colormaps.get_cmap(COLORMAP_NAME).resampled(len(CLASS_MAPPING))\n",
    "        num_classes = len(CLASS_MAPPING)\n",
    "\n",
    "        # Charger l'image originale et l'annotation\n",
    "        original_image = Image.open(image_path)\n",
    "        gt_image = Image.open(gt_mask_path)\n",
    "        pred_image = Image.open(pred_mask_path)\n",
    "\n",
    "        gt_mask = np.array(gt_image)\n",
    "        pred_mask = np.array(pred_image)\n",
    "        # Cr√©er la figure avec 3 colonnes\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Image originale\n",
    "        axes[0].imshow(original_image)\n",
    "        axes[0].set_title(f\"Image : {image_path.name}\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        # Overlay avec Ground Truth\n",
    "        axes[1].imshow(original_image)\n",
    "        axes[1].imshow(gt_mask, cmap=color_map, alpha=0.5, vmin=0, vmax=len(CLASS_MAPPING)-1)\n",
    "        axes[1].set_title(\"Overlay Ground Truth\", fontsize=12, fontweight='bold')\n",
    "        axes[1].axis(\"off\")\n",
    "        \n",
    "        # Overlay avec Pr√©diction\n",
    "        axes[2].imshow(original_image)\n",
    "        axes[2].imshow(pred_mask, cmap=color_map, alpha=0.5, vmin=0, vmax=len(CLASS_MAPPING)-1)\n",
    "        axes[2].set_title(\"Overlay Pr√©diction\", fontsize=12, fontweight='bold')\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        # Ajouter les l√©gendes\n",
    "        legend_elements = get_legend_elements(pred_mask, id_to_class, color_map, num_classes)\n",
    "        axes[1].legend(handles=legend_elements, **LEGEND_CONFIG)\n",
    "        axes[2].legend(handles=legend_elements, **LEGEND_CONFIG)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Afficher la comparaison pour les premi√®res images\n",
    "if image_paths and gt_mask_paths and pred_mask_paths:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPARAISON VISUELLE : GROUND TRUTH vs PR√âDICTIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    display_comparison_with_ground_truth(\n",
    "        image_paths, gt_mask_paths, pred_mask_paths\n",
    "    )\n",
    "else:\n",
    "    print(\"Aucun r√©sultat de segmentation √† comparer.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-2 (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
