{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f057c3b6",
   "metadata": {},
   "source": [
    "# Projet 2 - Fashion Trend Intelligence | Segmentation vestimentaire avec IA\n",
    "\n",
    "Ce notebook permet d’évaluer la faisabilité technique du modèle SegFormer-clothes, afin de déterminer s’il est capable d’identifier et d’isoler avec précision chaque pièce vestimentaire présente dans une image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e7c8a",
   "metadata": {},
   "source": [
    "## 1. Installation du projet et de son environnement\n",
    "\n",
    "Afin d’utiliser correctement ce notebook, vérifiez que vous disposez du bon environnement pour l’exécuter.\n",
    "\n",
    "\n",
    "### 1.1 Installation de Python\n",
    "\n",
    "Pour ce projet, il est nécessaire d’avoir **au minimum Python 3.8**.  \n",
    "Si ce n’est pas déjà le cas, vous pouvez vous référer à [la documentation officielle](https://www.python.org/downloads/).\n",
    "\n",
    "Vérifiez votre version de Python :\n",
    "\n",
    "```bash\n",
    "python --version\n",
    "```\n",
    "\n",
    "### 1.2 Installation de `uv`\n",
    "\n",
    "`uv` est un gestionnaire de projets Python permettant d’installer et d’organiser les dépendances plus rapidement et plus simplement que les outils traditionnels (`pip`, `virtualenv`, etc.).\n",
    "\n",
    "Pour installer `uv`, veuillez suivre [la documentation officielle](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer)\n",
    "\n",
    "Vérifiez l’installation :\n",
    "\n",
    "```bash\n",
    "uv --version\n",
    "```\n",
    "\n",
    "### 1.3 Création du projet\n",
    "\n",
    "Créez un nouveau projet Python avec `uv` :\n",
    "\n",
    "```bash\n",
    "uv init nom_du_projet\n",
    "cd nom_du_projet\n",
    "```\n",
    "\n",
    "La structure de base du projet est alors générée automatiquement.\n",
    "\n",
    "\n",
    "### 1.4 Création et activation de l’environnement virtuel\n",
    "\n",
    "Créez l’environnement virtuel :\n",
    "\n",
    "```bash\n",
    "uv venv\n",
    "```\n",
    "\n",
    "Activez-le selon votre système :\n",
    "\n",
    "* **Linux / macOS**\n",
    "\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "* **Windows (PowerShell)**\n",
    "\n",
    "```powershell\n",
    ".venv\\Scripts\\Activate.ps1\n",
    "```\n",
    "\n",
    "Voir la documentation officielle :\n",
    "[https://docs.astral.sh/uv/pip/environments/#creating-a-virtual-environment](https://docs.astral.sh/uv/pip/environments/#creating-a-virtual-environment)\n",
    "\n",
    "\n",
    "\n",
    "### 1.5 Installation des dépendances\n",
    "\n",
    "> ❗ Assurez-vous que l’environnement virtuel est **activé** avant d’installer les dépendances.\n",
    "\n",
    "Installez les bibliothèques nécessaires au projet :\n",
    "\n",
    "```bash\n",
    "uv add ipykernel jupyterlab requests pillow matplotlib numpy tqdm python-dotenv\n",
    "```\n",
    "\n",
    "Ces dépendances sont automatiquement enregistrées dans le fichier `pyproject.toml`.\n",
    "\n",
    "Vous pouvez visualiser l’ensemble des dépendances installées avec la commande suivante :\n",
    "\n",
    "```bash\n",
    "uv tree\n",
    "```\n",
    "\n",
    "### 1.6 Création du fichier `.env`\n",
    "\n",
    "Créez un fichier nommé `.env` à la racine du projet.\n",
    "\n",
    "Copiez-y le contenu suivant et remplacez les valeurs si nécessaire :\n",
    "\n",
    "```env\n",
    "# Token d'authentification à l'API Hugging Face\n",
    "HF_API_TOKEN=VOTRE_TOKEN_HUGGING_FACE_ICI\n",
    "\n",
    "# Chemins du dataset\n",
    "DATASET_IMAGES_DIR=content/images_a_segmenter\n",
    "DATASET_ANNOTATIONS_DIR=content/annotations\n",
    "```\n",
    "\n",
    "⚠️ **Important** :\n",
    "\n",
    "* Ne partagez jamais votre fichier `.env`\n",
    "* Ajoutez-le à votre `.gitignore`\n",
    "\n",
    "```gitignore\n",
    ".env\n",
    "```\n",
    "\n",
    "### 1.7 Création d’un token Hugging Face\n",
    "\n",
    "1. Créez un compte sur [https://huggingface.co/](https://huggingface.co/)\n",
    "2. Allez dans **Profile → Settings → Access Tokens**\n",
    "3. Créez un nouveau token (rôle **read** suffisant)\n",
    "4. Copiez le token dans la variable `HF_API_TOKEN` du fichier `.env`\n",
    "\n",
    "\n",
    "### 1.8 Préparation des jeux de données\n",
    "\n",
    "Récupérez les jeux de données (images et annotations) et placez-les dans les dossiers suivants :\n",
    "\n",
    "```\n",
    "content/\n",
    "├── images_a_segmenter/\n",
    "│   ├── image_0.jpg\n",
    "│   ├── image_1.jpg\n",
    "│   └── ...\n",
    "└── annotations/\n",
    "    ├── mask_0.json\n",
    "    ├── mask_1.json\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87239d3",
   "metadata": {},
   "source": [
    "## 2. Importation des Bibliothèques\n",
    "\n",
    "Commençons par importer les bibliothèques Python nécessaires. Nous aurons besoin de :\n",
    "- **`os`** : Interaction avec le système de fichiers (navigation dans les répertoires, listage des fichiers images).\n",
    "- **`requests`** : Envoi de requêtes HTTP vers l'API pour la segmentation d'images.\n",
    "- **`PIL (Pillow)`** : Manipulation et traitement des images (ouverture, redimensionnement, conversion).\n",
    "- **`matplotlib.pyplot`** : Visualisation des images originales et des masques de segmentation.\n",
    "- **`matplotlib.patches`** : Création d'éléments graphiques personnalisés pour les légendes des visualisations.\n",
    "- **`numpy`** : Manipulation efficace des tableaux numériques représentant les pixels des images.\n",
    "- **`tqdm.notebook`** : Affichage d'une barre de progression interactive dans les notebooks Jupyter (utile lors du traitement par lot).\n",
    "- **`base64`** : Encodage/décodage en Base64 des images et masques échangés avec l'API.\n",
    "- **`io`** : Gestion des flux de données en mémoire pour la manipulation des images sans fichiers temporaires.\n",
    "- **`python-dotenv`** : Chargement sécurisé des variables d'environnement (comme les clés API) depuis un fichier `.env`.\n",
    "- **`time`** : Gestion des délais entre les appels API pour respecter les limites de taux (rate limiting).\n",
    "- **`re`** : Traitement d'expressions régulières (parsing de réponses, validation de formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41d4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import base64\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d06005",
   "metadata": {},
   "source": [
    "## 3. Chargement de la Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b649df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dossier 'content/images_a_segmenter' existant.\n",
      "✓ Dossier 'content/annotations' existant.\n"
     ]
    }
   ],
   "source": [
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Récupération des variables d'environnement\n",
    "image_dir = os.getenv('DATASET_IMAGES_DIR')\n",
    "annotations_dir = os.getenv('DATASET_ANNOTATIONS_DIR')\n",
    "api_token = os.getenv('HF_API_TOKEN')\n",
    "max_images = 50  # Nombre maximum d'images à traiter\n",
    "\n",
    "# Vérification de la présence des variables\n",
    "if not image_dir or not api_token or not annotations_dir:\n",
    "    raise ValueError(\"Variables d'environnement manquantes dans le fichier .env\")\n",
    "\n",
    "# Vérification du token\n",
    "if api_token == \"VOTRE_TOKEN_HUGGING_FACE_ICI\":\n",
    "    raise ValueError(\"Vous devez remplacer 'VOTRE_TOKEN_HUGGING_FACE_ICI' par votre token API personnel dans le fichier .env\")\n",
    "\n",
    "# Création des dossiers s'ils n'existent pas\n",
    "for directory, name in [(image_dir, \"images\"), (annotations_dir, \"annotations\")]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"✓ Dossier '{directory}' créé pour les {name}.\")\n",
    "    else:\n",
    "        print(f\"✓ Dossier '{directory}' existant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095821a",
   "metadata": {},
   "source": [
    "## 3. Configuration de l'API Hugging Face\n",
    "\n",
    "### Présentation du modèle\n",
    "Nous utilisons le modèle [**SegFormer-B3-Clothes**](https://huggingface.co/sayeed99/segformer_b3_clothes) qui est spécialisé dans la segmentation sémantique de vêtements. Ce modèle peut détecter 18 classes différentes :\n",
    "- Éléments vestimentaires : chapeau, haut, jupe, pantalon, robe, ceinture, chaussures, sac, écharpe\n",
    "- Parties du corps : cheveux, visage, bras, jambes\n",
    "- Accessoires : lunettes de soleil\n",
    "- Arrière-plan\n",
    "\n",
    "### Configuration de l'endpoint API\n",
    "L'API Hugging Face Inference Router permet d'interroger le modèle sans avoir à le déployer localement. Voici les éléments de configuration :\n",
    "\n",
    "**URL de l'API** : `https://router.huggingface.co/hf-inference/models/sayeed99/segformer_b3_clothes`\n",
    "\n",
    "**Headers requis** :\n",
    "- `Authorization: Bearer YOUR_TOKEN` : Authentification avec votre token personnel\n",
    "- `Content-Type: image/jpeg` ou `image/png` : Type MIME de l'image envoyée\n",
    "\n",
    "**Format de réponse** : L'API retourne un JSON contenant une liste de masques encodés en base64, un par classe détectée.\n",
    "\n",
    "**Sécurité** : Ne jamais hardcoder votre token dans le notebook. Elle doit mis dans la variable d'environnement `HF_API_TOKEN'` le fichier `.env`\n",
    "\n",
    "### Bonnes pratiques d'utilisation\n",
    "1. **Rate Limiting** : Espacer les requêtes de 1-2 secondes pour éviter les erreurs 429 (Too Many Requests)\n",
    "2. **Timeout** : Définir un timeout de 30 secondes minimum (le modèle peut être lent)\n",
    "3. **Gestion d'erreurs** : Prévoir les cas suivants :\n",
    "   - 401 : Token invalide\n",
    "   - 429 : Trop de requêtes\n",
    "   - 500 : Erreur serveur (réessayer après quelques secondes)\n",
    "   - 503 : Modèle en cours de chargement (attendre et réessayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://router.huggingface.co/hf-inference/models/sayeed99/segformer_b3_clothes\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\"\n",
    "    # Le \"Content-Type\" sera ajouté dynamiquement lors de l'envoi de l'image\n",
    "}\n",
    "\n",
    "\n",
    "def request_cloth_segmentation(single_image_path):\n",
    "    \"\"\"\n",
    "    Requête à l'API Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        single_image_path (str): Chemin vers l'image à segmenter\n",
    "\n",
    "    Returns:\n",
    "        dict: Résultats de la segmentation (JSON de l'API)\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: Si le fichier image n'existe pas\n",
    "        ValueError: Si le format d'image n'est pas supporté\n",
    "        requests.exceptions.RequestException: Si la requête API échoue\n",
    "    \"\"\"\n",
    "    \n",
    "    # On vérifie que le fichier existe\n",
    "    if not os.path.exists(single_image_path):\n",
    "        raise FileNotFoundError(f\"L'image '{single_image_path}' n'existe pas\")\n",
    "    \n",
    "    try:\n",
    "        # On ouvre l'image pour vérifier le format (une seule fois)\n",
    "        with Image.open(single_image_path) as img:\n",
    "            image_format = img.format\n",
    "            \n",
    "            # On vérifie que le format est supporté\n",
    "            if image_format not in ['JPEG', 'PNG']:\n",
    "                raise ValueError(\n",
    "                    f\"Format '{image_format}' non supporté. \"\n",
    "                    f\"Formats acceptés: JPEG, PNG\"\n",
    "                )\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Erreur lors de l'ouverture de l'image (fichier corrompu, etc.)\n",
    "        raise ValueError(f\"Impossible d'ouvrir l'image: {e}\")\n",
    "    \n",
    "    # Lire le contenu binaire de l'image\n",
    "    try:\n",
    "        with open(single_image_path, 'rb') as fichier:\n",
    "            image_data = fichier.read()\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"Erreur lors de la lecture du fichier: {e}\")\n",
    "    \n",
    "    # On configure les headers avec le Content-Type\n",
    "    headers[\"Content-Type\"] = f\"image/{image_format.lower()}\"\n",
    "    \n",
    "    # On fait la requête POST à l'API\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            API_URL,\n",
    "            headers=headers,\n",
    "            data=image_data,\n",
    "            timeout=30  # Timeout de 30 secondes\n",
    "        )\n",
    "        print(f\"Réponse reçue pour {os.path.basename(single_image_path)}\")\n",
    "\n",
    "        # Si status >= 400 alors il y aura une exception\n",
    "        response.raise_for_status()\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        raise requests.exceptions.Timeout(\n",
    "            f\"Timeout lors de la requête API pour '{single_image_path}'\"\n",
    "        )\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        raise requests.exceptions.ConnectionError(\n",
    "            \"Impossible de se connecter à l'API Hugging Face\"\n",
    "        )\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        # Erreur HTTP (4xx, 5xx)\n",
    "        error_detail = \"\"\n",
    "        try:\n",
    "            error_detail = response.json().get('error', '')\n",
    "        except:\n",
    "            error_detail = response.text[:200]  # Premiers 200 caractères\n",
    "        \n",
    "        raise requests.exceptions.HTTPError(\n",
    "            f\"Erreur API (status {response.status_code}): {error_detail}\"\n",
    "        )\n",
    "    \n",
    "    # 6. Parser la réponse JSON\n",
    "    try:\n",
    "        results = response.json()\n",
    "        return results\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Réponse API invalide (pas du JSON): {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-2 (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
